---
title: "Variance Reduction Methods for High-Dimensional Optimal Control Problem"
excerpt: "This honor thesis is inspired and built upon my advisor Professor Ruthotto’s recent study [1] which formulates the neural network framework for solving high-dimensional optimal control prob- lems<br/><img src='/images/proposal.png'>"
collection: portfolio
---

This honor thesis is inspired and built upon my advisor Professor Ruthotto’s recent study [1] which formulates the neural network framework for solving high-dimensional optimal control prob- lems. The study [1] investigates a series of multi-agent optimal control problems with state-space dimensions ranging from 4 to 150. The study uses a grid-free numerical approach of parameter- izing the value function with a neural network and a hybrid system of the Pontryagin Maximum Principle (PMP) and Hamilton-Jacobi-Bellman (HJB) methods, effectively mitigating the CoD for high dimensional OC problems. Due to the high dimensionality nature of this approach, an effective optimizer that is both computationally and memory efficient is needed to facilitate the demanding training process for high-dimensional OC problems. The optimization problem in this study is solved by the ADAM algorithm. While this algorithm is computationally efficient, it re- quires many samples to converge. This honor thesis proposes an alternative optimization strategy for training the same neural networks on high-dimensional optimal control problems, allowing for more sampling efficiency and a similar convergence rate as the previous method. The introduced new method is the streaming stochastic variance-reduced gradient method [2], which is a vari- ance reduced stochastic optimization method suitable for solving the multi-agent optimal control problems with an infinite state-space set.


In this study, we implement the Streaming SVRG optimizer in PyTorch based on the algorithm [2], and applied it to various high-dimensional OC problems provided by the study [1]. In terms of high-dimensional optimal control problems, the setup in this thesis is similar to the method in [1]. We use the same adaptive sampling strategy to generate the initial states from a distribution with a specific density and set up the identical optimal control problems with the same neural networks parameters. The differences are: (1) The optimizer is the Streaming SVRG method while the previous method is ADAM; (2) The training structure and workflow are slightly different due to the newly adopted optimizer. We evaluate the effectiveness of these optimizers in terms of their gradient computational cost and running time. Furthermore, we investigate the relationship between the convergence rate and the parameters by tweaking the neural network parameters. In addition, we compare the effectiveness of these two optimizers in solving several multi-agent optimal control problems with state-space dimensions ranging from 4 to 150. Our preliminary results show that the SSVRG method requires five to ten times fewer gradient counts than ADAM with a similar convergence rate, which is sampling efficient and effectively reduces the training cost of large state-space optimization problems. The overall results of this study will contribute to the research in high-dimensional optimal control problems, especially multi-agent systems.


Reference 
1. Derek Onken, Levon Nurbekyan, Xingjian Li, Samy Wu Fung, Stanley Osher, and Lars Ruthotto. A neural network approach for high-dimensional optimal control. Michigan Health, 2021.
2. Sham M. Kakade Aaron Sidford Roy Frostig, Rong Ge. Competing with the empirical risk minimizer in a single pass. European journal of epidemiology, 2015.